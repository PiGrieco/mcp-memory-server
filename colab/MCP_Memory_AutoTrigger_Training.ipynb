{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🧠 MCP Memory Auto-Trigger Training on Google Colab A100\n",
        "\n",
        "This notebook trains a **WORLD-CLASS** auto-trigger model using **47K+ ULTIMATE examples** with **68% real data**.\n",
        "\n",
        "## 🎯 **ULTIMATE DATASET**\n",
        "**Dataset ID**: `PiGrieco/mcp-memory-auto-trigger-ultimate`\n",
        "\n",
        "**Requirements:**\n",
        "- Google Colab Pro/Pro+ with A100 GPU  \n",
        "- Hugging Face token (already available)\n",
        "- ~3-4 hours training time\n",
        "\n",
        "## 📊 **Dataset Composition (47,516 examples):**\n",
        "- **BANKING77**: 13,083 examples (27.5%) - Real financial data\n",
        "- **CLINC150**: 19,222 examples (40.5%) - Real intent classification\n",
        "- **Synthetic Original**: 5,255 examples (11.1%) - Advanced generation\n",
        "- **Synthetic Advanced**: 9,956 examples (21.0%) - English-optimized\n",
        "\n",
        "## 🌟 **WORLD-CLASS Quality:**\n",
        "- ✅ **68% Real Data** (exceptional quality!)\n",
        "- ✅ **100% Unique** (zero duplicates)\n",
        "- ✅ **100% English** (consistent language)\n",
        "- ✅ **Balanced Classes** (optimal distribution)\n",
        "\n",
        "## 📈 **Expected Performance:**\n",
        "- **Accuracy**: >**90%** (world-class!)\n",
        "- **F1-Score**: >**88%**\n",
        "- **Training Time**: 3-4 hours on A100\n",
        "- **Production Ready**: Immediate deployment\n",
        "\n",
        "**Ready for WORLD-CLASS results!** 🌟\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🚀 Install required packages for WORLD-CLASS training\n",
        "!pip install datasets transformers torch accelerate evaluate scikit-learn huggingface_hub wandb\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments, \n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import evaluate\n",
        "from huggingface_hub import login\n",
        "import wandb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"🚀 Libraries imported successfully!\")\n",
        "print(f\"⚡ PyTorch version: {torch.__version__}\")\n",
        "print(f\"🔥 CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"🎯 GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
        "    print(\"✅ Ready for WORLD-CLASS training!\")\n",
        "else:\n",
        "    print(\"⚠️ No GPU detected - training will be slower\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📂 Load ULTIMATE Dataset from Hugging Face Hub\n",
        "print(\"📂 Loading ULTIMATE dataset...\")\n",
        "\n",
        "# The dataset is already public, no token needed for loading\n",
        "dataset = load_dataset(\"PiGrieco/mcp-memory-auto-trigger-ultimate\")\n",
        "\n",
        "print(\"✅ Dataset loaded successfully!\")\n",
        "print(f\"📊 Dataset splits: {list(dataset.keys())}\")\n",
        "\n",
        "# Show dataset info\n",
        "for split_name, split_data in dataset.items():\n",
        "    print(f\"  📋 {split_name}: {len(split_data):,} examples\")\n",
        "\n",
        "# Analyze the dataset\n",
        "train_data = dataset['train']\n",
        "print(f\"\\n🔍 Dataset Analysis:\")\n",
        "print(f\"  📝 Sample text: \\\"{train_data[0]['text']}\\\"\")\n",
        "print(f\"  🎯 Label: {train_data[0]['label']} ({train_data[0]['label_name']})\")\n",
        "print(f\"  📚 Source: {train_data[0].get('source', 'unknown')}\")\n",
        "\n",
        "# Check label distribution\n",
        "labels = [ex['label'] for ex in train_data]\n",
        "from collections import Counter\n",
        "label_counts = Counter(labels)\n",
        "label_names = {0: \"SAVE_MEMORY\", 1: \"SEARCH_MEMORY\", 2: \"NO_ACTION\"}\n",
        "\n",
        "print(f\"\\n📊 Label Distribution:\")\n",
        "for label, count in label_counts.items():\n",
        "    label_name = label_names.get(label, f\"UNKNOWN_{label}\")\n",
        "    percentage = (count / len(train_data)) * 100\n",
        "    print(f\"  {label_name}: {count:,} examples ({percentage:.1f}%)\")\n",
        "\n",
        "print(f\"\\n🌟 ULTIMATE dataset ready for WORLD-CLASS training!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔐 Login to Hugging Face Hub for model upload\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "# Use your token for uploading the trained model\n",
        "# Set your token in Colab: !export HUGGINGFACE_TOKEN=your_token_here\n",
        "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\", \"your_hf_token_here\")\n",
        "if HF_TOKEN == \"your_hf_token_here\":\n",
        "    print(\"⚠️ Please set your HuggingFace token:\")\n",
        "    print(\"!export HUGGINGFACE_TOKEN=your_actual_token\")\n",
        "    print(\"Or set it manually: HF_TOKEN = 'your_token'\")\n",
        "else:\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"✅ Logged in to Hugging Face Hub!\")\n",
        "    print(\"🔄 Ready to upload trained model after training...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🤖 Load Model and Tokenizer for Training\n",
        "print(\"🤖 Loading DistilBERT model and tokenizer...\")\n",
        "\n",
        "# Model configuration\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "NUM_LABELS = 3  # SAVE_MEMORY, SEARCH_MEMORY, NO_ACTION\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Load model for sequence classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        "    id2label={0: \"SAVE_MEMORY\", 1: \"SEARCH_MEMORY\", 2: \"NO_ACTION\"},\n",
        "    label2id={\"SAVE_MEMORY\": 0, \"SEARCH_MEMORY\": 1, \"NO_ACTION\": 2}\n",
        ")\n",
        "\n",
        "print(f\"✅ Model loaded: {MODEL_NAME}\")\n",
        "print(f\"🎯 Number of labels: {NUM_LABELS}\")\n",
        "print(f\"⚙️ Model parameters: {model.num_parameters():,}\")\n",
        "\n",
        "# Check model is on GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print(f\"🔥 Model moved to: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔄 Tokenize Dataset for Training\n",
        "print(\"🔄 Tokenizing dataset...\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"Tokenize the text for BERT-style models\"\"\"\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=512,\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "# Tokenize all splits\n",
        "print(\"  📝 Tokenizing train set...\")\n",
        "tokenized_train = dataset['train'].map(tokenize_function, batched=True)\n",
        "\n",
        "print(\"  📝 Tokenizing validation set...\")\n",
        "tokenized_val = dataset['validation'].map(tokenize_function, batched=True)\n",
        "\n",
        "print(\"  📝 Tokenizing test set...\")\n",
        "tokenized_test = dataset['test'].map(tokenize_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "tokenized_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "tokenized_val.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "print(\"✅ Dataset tokenization complete!\")\n",
        "print(f\"  📊 Train: {len(tokenized_train):,} examples\")\n",
        "print(f\"  📊 Validation: {len(tokenized_val):,} examples\") \n",
        "print(f\"  📊 Test: {len(tokenized_test):,} examples\")\n",
        "\n",
        "# Data collator for dynamic padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📊 Setup Evaluation Metrics\n",
        "print(\"📊 Setting up evaluation metrics...\")\n",
        "\n",
        "# Load evaluation metric\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute metrics for evaluation\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    f1_macro = f1_metric.compute(predictions=predictions, references=labels, average='macro')\n",
        "    f1_weighted = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
        "    \n",
        "    # Additional metrics\n",
        "    precision, recall, f1_per_class, support = precision_recall_fscore_support(\n",
        "        labels, predictions, average=None\n",
        "    )\n",
        "    \n",
        "    # Class names for detailed metrics\n",
        "    class_names = [\"SAVE_MEMORY\", \"SEARCH_MEMORY\", \"NO_ACTION\"]\n",
        "    \n",
        "    metrics = {\n",
        "        'accuracy': accuracy['accuracy'],\n",
        "        'f1_macro': f1_macro['f1'],\n",
        "        'f1_weighted': f1_weighted['f1'],\n",
        "    }\n",
        "    \n",
        "    # Add per-class metrics\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        metrics[f'f1_{class_name}'] = f1_per_class[i]\n",
        "        metrics[f'precision_{class_name}'] = precision[i]\n",
        "        metrics[f'recall_{class_name}'] = recall[i]\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "print(\"✅ Evaluation metrics configured!\")\n",
        "print(\"  🎯 Metrics: Accuracy, F1 (macro/weighted), Per-class Precision/Recall\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🏋️ Training Configuration\n",
        "print(\"🏋️ Setting up training configuration...\")\n",
        "\n",
        "# Training arguments optimized for A100\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./mcp-memory-auto-trigger-results',\n",
        "    num_train_epochs=3,                    # 3 epochs for high-quality dataset\n",
        "    per_device_train_batch_size=32,        # Large batch size for A100\n",
        "    per_device_eval_batch_size=64,         # Larger batch for evaluation\n",
        "    warmup_steps=500,                      # Warmup steps\n",
        "    weight_decay=0.01,                     # Regularization\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,                     # Log every 100 steps\n",
        "    evaluation_strategy=\"steps\",           # Evaluate during training\n",
        "    eval_steps=500,                        # Evaluate every 500 steps\n",
        "    save_strategy=\"steps\",                 # Save checkpoints\n",
        "    save_steps=1000,                       # Save every 1000 steps\n",
        "    load_best_model_at_end=True,          # Load best model\n",
        "    metric_for_best_model=\"f1_macro\",     # Use F1 macro for best model\n",
        "    greater_is_better=True,               # Higher F1 is better\n",
        "    report_to=None,                       # Disable wandb for now\n",
        "    push_to_hub=False,                    # We'll push manually later\n",
        "    dataloader_num_workers=2,             # Parallel data loading\n",
        "    gradient_accumulation_steps=1,        # No gradient accumulation needed with large batches\n",
        "    learning_rate=2e-5,                   # Standard learning rate for DistilBERT\n",
        "    adam_epsilon=1e-8,                    # Adam optimizer epsilon\n",
        "    max_grad_norm=1.0,                    # Gradient clipping\n",
        "    seed=42,                              # Reproducibility\n",
        "    fp16=True,                            # Mixed precision training for speed\n",
        ")\n",
        "\n",
        "print(\"✅ Training configuration set!\")\n",
        "print(f\"  🎯 Epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"  📦 Batch size: {training_args.per_device_train_batch_size}\")\n",
        "print(f\"  📈 Learning rate: {training_args.learning_rate}\")\n",
        "print(f\"  ⚡ Mixed precision: {training_args.fp16}\")\n",
        "print(f\"  💾 Output dir: {training_args.output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🚀 Initialize Trainer and Start Training\n",
        "print(\"🚀 Initializing trainer...\")\n",
        "\n",
        "# Create trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"✅ Trainer initialized!\")\n",
        "print(\"🎯 Ready to start training...\")\n",
        "\n",
        "# Print training info\n",
        "total_train_steps = len(tokenized_train) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
        "print(f\"📊 Total training steps: {total_train_steps:,}\")\n",
        "print(f\"⏱️ Estimated training time: ~3-4 hours on A100\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"🔥 STARTING TRAINING!\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"🎉 TRAINING COMPLETED!\")\n",
        "print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📊 Final Evaluation on Test Set\n",
        "print(\"📊 Evaluating on test set...\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_results = trainer.evaluate(tokenized_test)\n",
        "\n",
        "print(\"✅ Test evaluation completed!\")\n",
        "print(\"\\n🎯 **FINAL RESULTS:**\")\n",
        "\n",
        "# Print key metrics\n",
        "print(f\"  📈 Accuracy: {test_results['eval_accuracy']:.4f} ({test_results['eval_accuracy']*100:.2f}%)\")\n",
        "print(f\"  🎯 F1 Macro: {test_results['eval_f1_macro']:.4f}\")\n",
        "print(f\"  ⚖️ F1 Weighted: {test_results['eval_f1_weighted']:.4f}\")\n",
        "\n",
        "print(f\"\\n📋 **PER-CLASS RESULTS:**\")\n",
        "class_names = [\"SAVE_MEMORY\", \"SEARCH_MEMORY\", \"NO_ACTION\"]\n",
        "for class_name in class_names:\n",
        "    f1 = test_results[f'eval_f1_{class_name}']\n",
        "    precision = test_results[f'eval_precision_{class_name}']\n",
        "    recall = test_results[f'eval_recall_{class_name}']\n",
        "    print(f\"  {class_name}:\")\n",
        "    print(f\"    F1: {f1:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n",
        "\n",
        "# Generate predictions for confusion matrix\n",
        "predictions = trainer.predict(tokenized_test)\n",
        "y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "y_true = predictions.label_ids\n",
        "\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix - MCP Memory Auto-Trigger')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "# Detailed classification report\n",
        "print(f\"\\n📄 **DETAILED CLASSIFICATION REPORT:**\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📤 Upload Trained Model to Hugging Face Hub\n",
        "print(\"📤 Uploading trained model to Hugging Face Hub...\")\n",
        "\n",
        "# Define model repository name\n",
        "MODEL_REPO_NAME = \"mcp-memory-auto-trigger-model\"\n",
        "MODEL_REPO_ID = f\"PiGrieco/{MODEL_REPO_NAME}\"\n",
        "\n",
        "print(f\"🎯 Uploading to: {MODEL_REPO_ID}\")\n",
        "\n",
        "# Push model and tokenizer to hub\n",
        "trainer.push_to_hub(\n",
        "    repo_id=MODEL_REPO_ID,\n",
        "    commit_message=\"🚀 Trained MCP Memory Auto-Trigger model on 47K world-class examples\",\n",
        "    private=False  # Make it public\n",
        ")\n",
        "\n",
        "print(\"✅ Model uploaded successfully!\")\n",
        "\n",
        "# Create model card content\n",
        "model_card_content = f\"\"\"\n",
        "# MCP Memory Auto-Trigger Model\n",
        "\n",
        "## Model Description\n",
        "\n",
        "This model was trained to automatically decide when to save information to memory, search existing memory, or take no action based on user conversations. It's designed for intelligent memory management in AI assistants.\n",
        "\n",
        "## Training Data\n",
        "\n",
        "- **Dataset**: PiGrieco/mcp-memory-auto-trigger-ultimate  \n",
        "- **Total Examples**: 47,516\n",
        "- **Real Data**: 68% (BANKING77, CLINC150)\n",
        "- **Synthetic Data**: 32% (high-quality generated)\n",
        "- **Language**: English\n",
        "\n",
        "## Performance\n",
        "\n",
        "- **Accuracy**: {test_results['eval_accuracy']:.4f} ({test_results['eval_accuracy']*100:.2f}%)\n",
        "- **F1 Macro**: {test_results['eval_f1_macro']:.4f}\n",
        "- **F1 Weighted**: {test_results['eval_f1_weighted']:.4f}\n",
        "\n",
        "## Classes\n",
        "\n",
        "- **SAVE_MEMORY** (0): Save important information to memory\n",
        "- **SEARCH_MEMORY** (1): Search for existing information in memory  \n",
        "- **NO_ACTION** (2): Normal conversation requiring no memory action\n",
        "\n",
        "## Usage\n",
        "\n",
        "```python\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"PiGrieco/{MODEL_REPO_NAME}\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"PiGrieco/{MODEL_REPO_NAME}\")\n",
        "\n",
        "# Example usage\n",
        "text = \"I need to remember this configuration setting for later\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    predicted_class = torch.argmax(predictions, dim=-1).item()\n",
        "\n",
        "class_names = [\"SAVE_MEMORY\", \"SEARCH_MEMORY\", \"NO_ACTION\"]\n",
        "print(f\"Predicted action: {{class_names[predicted_class]}}\")\n",
        "print(f\"Confidence: {{predictions[0][predicted_class]:.4f}}\")\n",
        "```\n",
        "\n",
        "## Training Details\n",
        "\n",
        "- **Base Model**: distilbert-base-uncased\n",
        "- **Training Framework**: Hugging Face Transformers\n",
        "- **Hardware**: Google Colab A100 GPU\n",
        "- **Training Time**: ~3-4 hours\n",
        "- **Epochs**: 3\n",
        "- **Batch Size**: 32\n",
        "- **Learning Rate**: 2e-5\n",
        "\n",
        "## Intended Use\n",
        "\n",
        "This model is designed for production use in MCP Memory Server systems to intelligently trigger memory operations based on conversational context.\n",
        "\"\"\"\n",
        "\n",
        "# Save model card\n",
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=model_card_content.encode(),\n",
        "    path_in_repo=\"README.md\",\n",
        "    repo_id=MODEL_REPO_ID,\n",
        "    repo_type=\"model\",\n",
        "    token=HF_TOKEN\n",
        ")\n",
        "\n",
        "print(\"✅ Model card uploaded!\")\n",
        "\n",
        "print(f\"\\n🎉 **DEPLOYMENT COMPLETE!**\")\n",
        "print(f\"🔗 **Model URL**: https://huggingface.co/{MODEL_REPO_ID}\")\n",
        "print(f\"📊 **Performance**: {test_results['eval_accuracy']*100:.2f}% accuracy\")\n",
        "print(f\"🚀 **Ready for production use!**\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
