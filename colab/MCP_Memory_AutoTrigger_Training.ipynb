{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† MCP Memory Auto-Trigger Training on Google Colab A100\n",
        "\n",
        "This notebook trains a **WORLD-CLASS** auto-trigger model using **47K+ ULTIMATE examples** with **68% real data**.\n",
        "\n",
        "## üéØ **ULTIMATE DATASET**\n",
        "**Dataset ID**: `PiGrieco/mcp-memory-auto-trigger-ultimate`\n",
        "\n",
        "**Requirements:**\n",
        "- Google Colab Pro/Pro+ with A100 GPU  \n",
        "- Hugging Face token (already available)\n",
        "- ~3-4 hours training time\n",
        "\n",
        "## üìä **Dataset Composition (47,516 examples):**\n",
        "- **BANKING77**: 13,083 examples (27.5%) - Real financial data\n",
        "- **CLINC150**: 19,222 examples (40.5%) - Real intent classification\n",
        "- **Synthetic Original**: 5,255 examples (11.1%) - Advanced generation\n",
        "- **Synthetic Advanced**: 9,956 examples (21.0%) - English-optimized\n",
        "\n",
        "## üåü **WORLD-CLASS Quality:**\n",
        "- ‚úÖ **68% Real Data** (exceptional quality!)\n",
        "- ‚úÖ **100% Unique** (zero duplicates)\n",
        "- ‚úÖ **100% English** (consistent language)\n",
        "- ‚úÖ **Balanced Classes** (optimal distribution)\n",
        "\n",
        "## üìà **Expected Performance:**\n",
        "- **Accuracy**: >**90%** (world-class!)\n",
        "- **F1-Score**: >**88%**\n",
        "- **Training Time**: 3-4 hours on A100\n",
        "- **Production Ready**: Immediate deployment\n",
        "\n",
        "**Ready for WORLD-CLASS results!** üåü\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ Install required packages for WORLD-CLASS training\n",
        "!pip install datasets transformers torch accelerate evaluate scikit-learn huggingface_hub wandb\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments, \n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import evaluate\n",
        "from huggingface_hub import login\n",
        "import wandb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"üöÄ Libraries imported successfully!\")\n",
        "print(f\"‚ö° PyTorch version: {torch.__version__}\")\n",
        "print(f\"üî• CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üéØ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
        "    print(\"‚úÖ Ready for WORLD-CLASS training!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU detected - training will be slower\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìÇ Load ULTIMATE Dataset from Hugging Face Hub\n",
        "print(\"üìÇ Loading ULTIMATE dataset...\")\n",
        "\n",
        "# The dataset is already public, no token needed for loading\n",
        "dataset = load_dataset(\"PiGrieco/mcp-memory-auto-trigger-ultimate\")\n",
        "\n",
        "print(\"‚úÖ Dataset loaded successfully!\")\n",
        "print(f\"üìä Dataset splits: {list(dataset.keys())}\")\n",
        "\n",
        "# Show dataset info\n",
        "for split_name, split_data in dataset.items():\n",
        "    print(f\"  üìã {split_name}: {len(split_data):,} examples\")\n",
        "\n",
        "# Analyze the dataset\n",
        "train_data = dataset['train']\n",
        "print(f\"\\nüîç Dataset Analysis:\")\n",
        "print(f\"  üìù Sample text: \\\"{train_data[0]['text']}\\\"\")\n",
        "print(f\"  üéØ Label: {train_data[0]['label']} ({train_data[0]['label_name']})\")\n",
        "print(f\"  üìö Source: {train_data[0].get('source', 'unknown')}\")\n",
        "\n",
        "# Check label distribution\n",
        "labels = [ex['label'] for ex in train_data]\n",
        "from collections import Counter\n",
        "label_counts = Counter(labels)\n",
        "label_names = {0: \"SAVE_MEMORY\", 1: \"SEARCH_MEMORY\", 2: \"NO_ACTION\"}\n",
        "\n",
        "print(f\"\\nüìä Label Distribution:\")\n",
        "for label, count in label_counts.items():\n",
        "    label_name = label_names.get(label, f\"UNKNOWN_{label}\")\n",
        "    percentage = (count / len(train_data)) * 100\n",
        "    print(f\"  {label_name}: {count:,} examples ({percentage:.1f}%)\")\n",
        "\n",
        "print(f\"\\nüåü ULTIMATE dataset ready for WORLD-CLASS training!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîê Login to Hugging Face Hub for model upload\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "# Use your token for uploading the trained model\n",
        "# Set your token in Colab: !export HUGGINGFACE_TOKEN=your_token_here\n",
        "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\", \"your_hf_token_here\")\n",
        "if HF_TOKEN == \"your_hf_token_here\":\n",
        "    print(\"‚ö†Ô∏è Please set your HuggingFace token:\")\n",
        "    print(\"!export HUGGINGFACE_TOKEN=your_actual_token\")\n",
        "    print(\"Or set it manually: HF_TOKEN = 'your_token'\")\n",
        "else:\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"‚úÖ Logged in to Hugging Face Hub!\")\n",
        "    print(\"üîÑ Ready to upload trained model after training...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ü§ñ Load Model and Tokenizer for Training\n",
        "print(\"ü§ñ Loading DistilBERT model and tokenizer...\")\n",
        "\n",
        "# Model configuration\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "NUM_LABELS = 3  # SAVE_MEMORY, SEARCH_MEMORY, NO_ACTION\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Load model for sequence classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        "    id2label={0: \"SAVE_MEMORY\", 1: \"SEARCH_MEMORY\", 2: \"NO_ACTION\"},\n",
        "    label2id={\"SAVE_MEMORY\": 0, \"SEARCH_MEMORY\": 1, \"NO_ACTION\": 2}\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Model loaded: {MODEL_NAME}\")\n",
        "print(f\"üéØ Number of labels: {NUM_LABELS}\")\n",
        "print(f\"‚öôÔ∏è Model parameters: {model.num_parameters():,}\")\n",
        "\n",
        "# Check model is on GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print(f\"üî• Model moved to: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîÑ Tokenize Dataset for Training\n",
        "print(\"üîÑ Tokenizing dataset...\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"Tokenize the text for BERT-style models\"\"\"\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=512,\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "# Tokenize all splits\n",
        "print(\"  üìù Tokenizing train set...\")\n",
        "tokenized_train = dataset['train'].map(tokenize_function, batched=True)\n",
        "\n",
        "print(\"  üìù Tokenizing validation set...\")\n",
        "tokenized_val = dataset['validation'].map(tokenize_function, batched=True)\n",
        "\n",
        "print(\"  üìù Tokenizing test set...\")\n",
        "tokenized_test = dataset['test'].map(tokenize_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "tokenized_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "tokenized_val.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "print(\"‚úÖ Dataset tokenization complete!\")\n",
        "print(f\"  üìä Train: {len(tokenized_train):,} examples\")\n",
        "print(f\"  üìä Validation: {len(tokenized_val):,} examples\") \n",
        "print(f\"  üìä Test: {len(tokenized_test):,} examples\")\n",
        "\n",
        "# Data collator for dynamic padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìä Setup Evaluation Metrics\n",
        "print(\"üìä Setting up evaluation metrics...\")\n",
        "\n",
        "# Load evaluation metric\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute metrics for evaluation\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    f1_macro = f1_metric.compute(predictions=predictions, references=labels, average='macro')\n",
        "    f1_weighted = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
        "    \n",
        "    # Additional metrics\n",
        "    precision, recall, f1_per_class, support = precision_recall_fscore_support(\n",
        "        labels, predictions, average=None\n",
        "    )\n",
        "    \n",
        "    # Class names for detailed metrics\n",
        "    class_names = [\"SAVE_MEMORY\", \"SEARCH_MEMORY\", \"NO_ACTION\"]\n",
        "    \n",
        "    metrics = {\n",
        "        'accuracy': accuracy['accuracy'],\n",
        "        'f1_macro': f1_macro['f1'],\n",
        "        'f1_weighted': f1_weighted['f1'],\n",
        "    }\n",
        "    \n",
        "    # Add per-class metrics\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        metrics[f'f1_{class_name}'] = f1_per_class[i]\n",
        "        metrics[f'precision_{class_name}'] = precision[i]\n",
        "        metrics[f'recall_{class_name}'] = recall[i]\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "print(\"‚úÖ Evaluation metrics configured!\")\n",
        "print(\"  üéØ Metrics: Accuracy, F1 (macro/weighted), Per-class Precision/Recall\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üèãÔ∏è Training Configuration\n",
        "print(\"üèãÔ∏è Setting up training configuration...\")\n",
        "\n",
        "# Training arguments optimized for A100\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./mcp-memory-auto-trigger-results',\n",
        "    num_train_epochs=3,                    # 3 epochs for high-quality dataset\n",
        "    per_device_train_batch_size=32,        # Large batch size for A100\n",
        "    per_device_eval_batch_size=64,         # Larger batch for evaluation\n",
        "    warmup_steps=500,                      # Warmup steps\n",
        "    weight_decay=0.01,                     # Regularization\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,                     # Log every 100 steps\n",
        "    evaluation_strategy=\"steps\",           # Evaluate during training\n",
        "    eval_steps=500,                        # Evaluate every 500 steps\n",
        "    save_strategy=\"steps\",                 # Save checkpoints\n",
        "    save_steps=1000,                       # Save every 1000 steps\n",
        "    load_best_model_at_end=True,          # Load best model\n",
        "    metric_for_best_model=\"f1_macro\",     # Use F1 macro for best model\n",
        "    greater_is_better=True,               # Higher F1 is better\n",
        "    report_to=None,                       # Disable wandb for now\n",
        "    push_to_hub=False,                    # We'll push manually later\n",
        "    dataloader_num_workers=2,             # Parallel data loading\n",
        "    gradient_accumulation_steps=1,        # No gradient accumulation needed with large batches\n",
        "    learning_rate=2e-5,                   # Standard learning rate for DistilBERT\n",
        "    adam_epsilon=1e-8,                    # Adam optimizer epsilon\n",
        "    max_grad_norm=1.0,                    # Gradient clipping\n",
        "    seed=42,                              # Reproducibility\n",
        "    fp16=True,                            # Mixed precision training for speed\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Training configuration set!\")\n",
        "print(f\"  üéØ Epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"  üì¶ Batch size: {training_args.per_device_train_batch_size}\")\n",
        "print(f\"  üìà Learning rate: {training_args.learning_rate}\")\n",
        "print(f\"  ‚ö° Mixed precision: {training_args.fp16}\")\n",
        "print(f\"  üíæ Output dir: {training_args.output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ Initialize Trainer and Start Training\n",
        "print(\"üöÄ Initializing trainer...\")\n",
        "\n",
        "# Create trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Trainer initialized!\")\n",
        "print(\"üéØ Ready to start training...\")\n",
        "\n",
        "# Print training info\n",
        "total_train_steps = len(tokenized_train) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
        "print(f\"üìä Total training steps: {total_train_steps:,}\")\n",
        "print(f\"‚è±Ô∏è Estimated training time: ~3-4 hours on A100\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üî• STARTING TRAINING!\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üéâ TRAINING COMPLETED!\")\n",
        "print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìä Final Evaluation on Test Set\n",
        "print(\"üìä Evaluating on test set...\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_results = trainer.evaluate(tokenized_test)\n",
        "\n",
        "print(\"‚úÖ Test evaluation completed!\")\n",
        "print(\"\\nüéØ **FINAL RESULTS:**\")\n",
        "\n",
        "# Print key metrics\n",
        "print(f\"  üìà Accuracy: {test_results['eval_accuracy']:.4f} ({test_results['eval_accuracy']*100:.2f}%)\")\n",
        "print(f\"  üéØ F1 Macro: {test_results['eval_f1_macro']:.4f}\")\n",
        "print(f\"  ‚öñÔ∏è F1 Weighted: {test_results['eval_f1_weighted']:.4f}\")\n",
        "\n",
        "print(f\"\\nüìã **PER-CLASS RESULTS:**\")\n",
        "class_names = [\"SAVE_MEMORY\", \"SEARCH_MEMORY\", \"NO_ACTION\"]\n",
        "for class_name in class_names:\n",
        "    f1 = test_results[f'eval_f1_{class_name}']\n",
        "    precision = test_results[f'eval_precision_{class_name}']\n",
        "    recall = test_results[f'eval_recall_{class_name}']\n",
        "    print(f\"  {class_name}:\")\n",
        "    print(f\"    F1: {f1:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n",
        "\n",
        "# Generate predictions for confusion matrix\n",
        "predictions = trainer.predict(tokenized_test)\n",
        "y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "y_true = predictions.label_ids\n",
        "\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix - MCP Memory Auto-Trigger')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "# Detailed classification report\n",
        "print(f\"\\nüìÑ **DETAILED CLASSIFICATION REPORT:**\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì§ Upload Trained Model to Hugging Face Hub\n",
        "print(\"üì§ Uploading trained model to Hugging Face Hub...\")\n",
        "\n",
        "# Define model repository name\n",
        "MODEL_REPO_NAME = \"mcp-memory-auto-trigger-model\"\n",
        "MODEL_REPO_ID = f\"PiGrieco/{MODEL_REPO_NAME}\"\n",
        "\n",
        "print(f\"üéØ Uploading to: {MODEL_REPO_ID}\")\n",
        "\n",
        "# Push model and tokenizer to hub\n",
        "trainer.push_to_hub(\n",
        "    repo_id=MODEL_REPO_ID,\n",
        "    commit_message=\"üöÄ Trained MCP Memory Auto-Trigger model on 47K world-class examples\",\n",
        "    private=False  # Make it public\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model uploaded successfully!\")\n",
        "\n",
        "# Create model card content\n",
        "model_card_content = f\"\"\"\n",
        "# MCP Memory Auto-Trigger Model\n",
        "\n",
        "## Model Description\n",
        "\n",
        "This model was trained to automatically decide when to save information to memory, search existing memory, or take no action based on user conversations. It's designed for intelligent memory management in AI assistants.\n",
        "\n",
        "## Training Data\n",
        "\n",
        "- **Dataset**: PiGrieco/mcp-memory-auto-trigger-ultimate  \n",
        "- **Total Examples**: 47,516\n",
        "- **Real Data**: 68% (BANKING77, CLINC150)\n",
        "- **Synthetic Data**: 32% (high-quality generated)\n",
        "- **Language**: English\n",
        "\n",
        "## Performance\n",
        "\n",
        "- **Accuracy**: {test_results['eval_accuracy']:.4f} ({test_results['eval_accuracy']*100:.2f}%)\n",
        "- **F1 Macro**: {test_results['eval_f1_macro']:.4f}\n",
        "- **F1 Weighted**: {test_results['eval_f1_weighted']:.4f}\n",
        "\n",
        "## Classes\n",
        "\n",
        "- **SAVE_MEMORY** (0): Save important information to memory\n",
        "- **SEARCH_MEMORY** (1): Search for existing information in memory  \n",
        "- **NO_ACTION** (2): Normal conversation requiring no memory action\n",
        "\n",
        "## Usage\n",
        "\n",
        "```python\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"PiGrieco/{MODEL_REPO_NAME}\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"PiGrieco/{MODEL_REPO_NAME}\")\n",
        "\n",
        "# Example usage\n",
        "text = \"I need to remember this configuration setting for later\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    predicted_class = torch.argmax(predictions, dim=-1).item()\n",
        "\n",
        "class_names = [\"SAVE_MEMORY\", \"SEARCH_MEMORY\", \"NO_ACTION\"]\n",
        "print(f\"Predicted action: {{class_names[predicted_class]}}\")\n",
        "print(f\"Confidence: {{predictions[0][predicted_class]:.4f}}\")\n",
        "```\n",
        "\n",
        "## Training Details\n",
        "\n",
        "- **Base Model**: distilbert-base-uncased\n",
        "- **Training Framework**: Hugging Face Transformers\n",
        "- **Hardware**: Google Colab A100 GPU\n",
        "- **Training Time**: ~3-4 hours\n",
        "- **Epochs**: 3\n",
        "- **Batch Size**: 32\n",
        "- **Learning Rate**: 2e-5\n",
        "\n",
        "## Intended Use\n",
        "\n",
        "This model is designed for production use in MCP Memory Server systems to intelligently trigger memory operations based on conversational context.\n",
        "\"\"\"\n",
        "\n",
        "# Save model card\n",
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=model_card_content.encode(),\n",
        "    path_in_repo=\"README.md\",\n",
        "    repo_id=MODEL_REPO_ID,\n",
        "    repo_type=\"model\",\n",
        "    token=HF_TOKEN\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model card uploaded!\")\n",
        "\n",
        "print(f\"\\nüéâ **DEPLOYMENT COMPLETE!**\")\n",
        "print(f\"üîó **Model URL**: https://huggingface.co/{MODEL_REPO_ID}\")\n",
        "print(f\"üìä **Performance**: {test_results['eval_accuracy']*100:.2f}% accuracy\")\n",
        "print(f\"üöÄ **Ready for production use!**\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
